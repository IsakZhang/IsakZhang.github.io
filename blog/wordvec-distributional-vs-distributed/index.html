<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Word Vector - Distributional v.s. Distributed Representation · Isaac's NLP Blog</title><meta name="description" content="Word Vector - Distributional v.s. Distributed Representation - Isaac"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/blog/isaac.jpg"><link rel="stylesheet" href="/blog/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/blog/atom.xml" title="Isaac's NLP Blog"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/blog/atom.xml" title="Isaac's NLP Blog" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/blog/" class="logo-link"><img src="/blog/isaac-logo.jpg" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/blog/" target="_self" class="nav-list-link">POSTS</a></li><li class="nav-list-item"><a href="/blog/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/blog/../" target="_self" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Word Vector - Distributional v.s. Distributed Representation</h1><div class="post-info">Jun 25, 2020</div><div class="post-content"><p>提到词向量的时候，一般不可避免的会接触到 “Distributional Representation”，“Distributed Representation” 和 “Distributional Hypothesis” 这几个术语。由于它们长得非常像，许多地方也把前两者都翻译成“分布式表示”，所以就更加容易弄混了（至少我刚接触到的时候以为它们是一个东西 🤦‍♂️）。这两天偶然看到了 Goldberg 那本书中对这几个术语的区分，觉得非常清晰，所以这里结合自己的理解谈一下这几个术语到底代表什么。</p>
<p>P.S. 因为他们中文都带有“分布式”的意思，所以为了避免引起误解，全文这些词语就都用英文表示了。</p>
<h2 id="Background-Word-Representation"><a href="#Background-Word-Representation" class="headerlink" title="Background: Word Representation"></a>Background: Word Representation</h2><p>计算机显然无法直接处理原始的文本信息，所以在 NLP 中，如何把一个文本（词语/句子/段落/……）转化为一个计算机可以处理的数值型数据（通常是一个向量）是一个非常重要的问题，一般被笼统的称为文本表示。而将较长的文本（例如一段话或者一整篇文章）转化为一个向量显示比较困难，许多研究都集中在最小的粒度，也就是如何将一个词语 word 转化为一个向量，得到的向量通常被称为 Word Vector/Embedding/Representation。</p>
<p>至于如何（从大规模文本语料中）得到这样的 word vector，这就引出了“Distributional Representation” 和 “Distributed Representation” 这两种思路。值得注意的是它们并不是具体的算法（例如 word2vec, glove 或者最近一两年的 contextualized word vector 例如 BERT 等），所以本文中不会详细介绍如何得到 word vector 的方法。</p>
<h2 id="Distributional-Representation"><a href="#Distributional-Representation" class="headerlink" title="Distributional Representation"></a>Distributional Representation</h2><p>Distributional Semantics 的假说认为一个词语的词义可以从它在语料库中的分布得到体现，也就是说通过观察一个词出现的上下文(context)，我们可以了解到这个词的语义。这应该也是每个 NLPer 都听说过的那句话：</p>
<blockquote>
<p>You shall know a word by the company it keeps (Firth, 1957)</p>
</blockquote>
<p>由这种思路出发，为了找到词语的 distributional properties，人们一般建立一个 词语-上下文矩阵 (Word-Context Matrix) M。这个矩阵 M 的每一行对应一个词语，每一列对应着一种上下文关系，比较常见的例子是每一行代表一个词语，每一列代表在这个词语的周围一个小的 context window 中，另一个词语的共现频率；又或者通过计算 PMI/PPMI 来得到这样的矩阵。无论怎么来定义这样的矩阵，当得到 M 以后，我们其实就可以认为这个矩阵的每一行就是对应词语的一个 word vector，因为很容易想到，出现在相似语境下的两个词语的对应向量是会很相似的。</p>
<p>然而这个矩阵一般列数会非常大，导致得到的词向量维度非常高，为了得到低维/稠密向量，可以对其进行 SVD 分解然后降维，就可以得到一个低维的词向量，不过这个已经不是本篇讨论的重点了。</p>
<p>与 “distributional representations” 相对的是 “non-distributional representations”，例如不通过分析词语出现的上下文语境，而是通过构建 lexical resource 例如 WordNet 这种分析一个词的语义信息。</p>
<h2 id="Distributed-Representations"><a href="#Distributed-Representations" class="headerlink" title="Distributed Representations"></a>Distributed Representations</h2><p>在 distributed representation 中，强调的重点是每个词并非采用离散的表征方式（例如 one-hot encoding），而是被表征为一个低维，稠密的向量。具体来讲，在 one-hot encoding 中，每个词都是表示成一个 |V| 维的向量，只有自己对应的维度值为1，其他全部为0。例如：</p>
<p>$$w^{aardvark}=\begin{bmatrix} 1\0\0\ \vdots\0 \end{bmatrix}, w^{a}=\begin{bmatrix} 0\1\0\ \vdots\0 \end{bmatrix}, w^{at}=\begin{bmatrix} 0\0\1\ \vdots\0 \end{bmatrix}…, w^{zebra}=\begin{bmatrix} 0\0\0\ \vdots\1 \end{bmatrix}$$</p>
<p>而 distributed representation 强调的是每个词都对应着一个低维（例如100维）的向量，这个词的“词义”或者这个词与其他词的关系就蕴含在这个向量的不同维度中，例如题图中例子，但是我们一般并不知道每个维度对应着什么含义。</p>
<p>以较为早期的 <a target="_blank" rel="noopener" href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">Neural Language Model</a> 为例，每个词对应着最初 Embedding 矩阵的一行或者 最后 softmax 之前参数矩阵的一列，当随机初始化这些参数以后，training 的过程会自动决定什么样的 embedding 才是好的（才可以使得目标词汇的概率值最大）。</p>
<h2 id="Connections"><a href="#Connections" class="headerlink" title="Connections"></a>Connections</h2><p>从我的观点来看这两种 “representation” 并不是对立关系，只是侧重的角度不一样，前一种是说词的意义可以从语境中得出，后一种则是强调每个词可以由一个低维稠密的向量表示（而不是离散表示）。</p>
<p>如果从可解释角度出发，Distributed Representations 得到的向量中各个维度有没有什么明确的对应语义解释，而 distributional representations 中从 word-context matrix 得到的词向量的每一项是有明确的语义关系的（例如第3维表示 dog 和这个词语的共现频率）。然而如果用 SVD 分解后，得到的低维向量也同样没有十分明确的意义了。</p>
<p>其实无论哪种思路，具体到目前较为流行的各个算法上（例如无论是分解词语共现矩阵或者通过预测下一个词来自动“学习”），都是基于 distributional hypothesis，也即试图通过上下文之间的相似性来表述词语之间的相似性。在 Neural word embedding as implicit matrix factorization 这篇文章中，也证明了 skip-gram 和基于 PMI 矩阵的矩阵分解之间的等价性，所以也可以说是殊(?)途同归吧。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="http://phontron.com/class/nn4nlp2019/assets/slides/nn4nlp-03-wordemb.pdf">Word Embedding Slide of CMU CS11-747</a></li>
<li><a target="_blank" rel="noopener" href="https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037">Neural Network Methods for NLP</a>, Goldberg, Chapter 10</li>
</ul>
</div></article></div></main><footer><div class="paginator"><a href="/blog/cs-tutorials/" class="next">NEXT</a></div><div class="copyright"><p>© 2019 - 2021 <a href="http://yoursite.com/blog">Isaac</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>